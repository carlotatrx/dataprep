qc_root   <- "/scratch3/PALAEO-RA/daily_data/tmp/sef_tests"
# -----------------------------
# OUTPUT LIST OF SUCCESSFUL MATCHES
# -----------------------------
successful_matches <- list()
# -----------------------------
# RECURSIVELY LIST ALL FILES
# -----------------------------
orig_files <- list.files(orig_root, pattern = "\\.tsv$", recursive = TRUE, full.names = TRUE)
head(orig_files)
orig<-orig_files[1]
orig
fname <- basename(orig)
# Skip QC files
if (grepl("_qc\\.tsv$", fname)) {
next
}
orig_files
orig<-orig_files[5]
orig
fname <- basename(orig)
# Skip QC files
if (grepl("_qc\\.tsv$", fname)) {
next
}
# Construct expected QC filename
qc_fname <- sub("\\.tsv$", "_qc.tsv", fname)
qc_path <- file.path(qc_root, qc_fname)
# ----------------------------------
# CHECK IF QC FILE EXISTS
# ----------------------------------
if (!file.exists(qc_path)) {
warning(glue("QC file missing for: {fname}"))
next
}
# ----------------------------------
# READ HEADER LINES FROM BOTH FILES
# ----------------------------------
orig_lines <- read_lines(orig, n_max = 50)
orig_lines
qc_lines   <- read_lines(qc_path, n_max = 50)
# Header ends just before "Year"
orig_header <- orig_lines[1:(grep("^Year", orig_lines)[1] - 1)]
orig_header
qc_header   <- qc_lines[1:(grep("^Year", qc_lines)[1] - 1)]
# ----------------------------------
# CHECK HEADERS MATCH (EXCEPT META)
# ----------------------------------
# Copy headers so we can modify them
oh <- orig_header
qh <- qc_header
# Remove QC software tag from QC header's Meta line
if (any(grepl("^Meta", qh))) {
qh[grep("^Meta", qh)] <- sub(" \\| QC software=.*$", "", qh[grep("^Meta", qh)])
}
qh
oh
qh
qc_header
# Compare headers
if (!identical(oh, qh)) {
warning(glue("Header mismatch for {fname}"))
next
}
identical(oh,qh)
# ----------------------------------
# CHECK BODY DIMENSIONS MATCH
# ----------------------------------
orig_df <- try(read_tsv(orig, skip = length(orig_header), show_col_types = FALSE), silent = TRUE)
orig_df
qc_df   <- try(read_tsv(qc_path, skip = length(qc_header), show_col_types = FALSE), silent = TRUE)
qc_df
if (inherits(orig_df, "try-error") || inherits(qc_df, "try-error")) {
warning(glue("Error reading dataframes for {fname}"))
next
}
if (!all(dim(orig_df) == dim(qc_df))) {
warning(glue("Dimension mismatch for {fname}"))
next
}
# ----------------------------------
# IF WE GET HERE → SUCCESS
# ----------------------------------
successful_matches[[length(successful_matches) + 1]] <- list(
file = fname,
original_path = orig,
qc_path = qc_path
)
successful_matches
# -----------------------------
# LOOP THROUGH ORIGINAL FILES
# -----------------------------
for (orig in orig_files) {
fname <- basename(orig)
# Skip QC files
if (grepl("_qc\\.tsv$", fname)) {
next
}
# Construct expected QC filename
qc_fname <- sub("\\.tsv$", "_qc.tsv", fname)
qc_path <- file.path(qc_root, qc_fname)
# ----------------------------------
# CHECK IF QC FILE EXISTS
# ----------------------------------
if (!file.exists(qc_path)) {
warning(glue("QC file missing for: {fname}"))
next
}
# ----------------------------------
# READ HEADER LINES FROM BOTH FILES
# ----------------------------------
orig_lines <- read_lines(orig, n_max = 50)
qc_lines   <- read_lines(qc_path, n_max = 50)
# extract SEF header
orig_header <- orig_lines[1:(grep("^Year", orig_lines)[1] - 1)]
qc_header   <- qc_lines[1:(grep("^Year", qc_lines)[1] - 1)]
# ----------------------------------
# CHECK HEADERS MATCH (EXCEPT META)
# ----------------------------------
# Copy headers so we can modify them
oh <- orig_header
qh <- qc_header
# Remove QC software tag from QC header's Meta line
if (any(grepl("^Meta", qh))) {
qh[grep("^Meta", qh)] <- sub(" \\| QC software=.*$", "", qh[grep("^Meta", qh)])
}
# Compare headers
if (!identical(oh, qh)) {
warning(glue("Header mismatch for {fname}"))
next
}
# ----------------------------------
# CHECK BODY DIMENSIONS MATCH
# ----------------------------------
orig_df <- try(read_tsv(orig, skip = length(orig_header), show_col_types = FALSE), silent = TRUE)
qc_df   <- try(read_tsv(qc_path, skip = length(qc_header), show_col_types = FALSE), silent = TRUE)
if (inherits(orig_df, "try-error") || inherits(qc_df, "try-error")) {
warning(glue("Error reading dataframes for {fname}"))
next
}
if (!all(dim(orig_df) == dim(qc_df))) {
warning(glue("Dimension mismatch for {fname}"))
next
}
# ----------------------------------
# IF WE GET HERE → SUCCESS
# ----------------------------------
successful_matches[[length(successful_matches) + 1]] <- list(
file = fname,
original_path = orig,
qc_path = qc_path
)
}
warnings()
successful_matches
len(orig_files)
length(orig_files)
length(qc_files)
warnings()
# -----------------------------
# VARIABLES THAT DO NOT HAVE QC FILES
# -----------------------------
no_qc_vars <- c("w", "eee")
source("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
# -----------------------------
# LOOP THROUGH ORIGINAL FILES
# -----------------------------
for (orig in orig_files) {
fname <- basename(orig)
# Skip QC files
if (grepl("_qc\\.tsv$", fname)) {
next
}
# check variable and skip those that don't have qc's done on them.
header_lines <- read_lines(orig, n_max=20)
var_line     <- header_lines[grepl("^Vbl", header_lines)]
var          <- sub("^Vbl\\s+", "", var_line)
# Construct expected QC filename
qc_fname <- sub("\\.tsv$", "_qc.tsv", fname)
qc_path <- file.path(qc_root, qc_fname)
# ----------------------------------
# SKIP CHECKS OF NON-QC VARS
# ----------------------------------
if (var %in% no_qc_vars && !file.exists(qc_path)) {
# silent skip
next
}
# ----------------------------------
# CHECK IF QC FILE IS MISSING
# ----------------------------------
if (!file.exists(qc_path)) {
warning(glue("QC file missing for: {fname}"))
next
}
# ----------------------------------
# READ HEADER LINES FROM BOTH FILES
# ----------------------------------
orig_lines <- read_lines(orig, n_max = 50)
qc_lines   <- read_lines(qc_path, n_max = 50)
# extract SEF header
orig_header <- orig_lines[1:(grep("^Year", orig_lines)[1] - 1)]
qc_header   <- qc_lines[1:(grep("^Year", qc_lines)[1] - 1)]
# ----------------------------------
# CHECK HEADERS MATCH (inkl. META)
# ----------------------------------
# Copy headers so we can modify them
oh <- orig_header
qh <- qc_header
# Remove QC software tag from QC header's Meta line
# Find Meta lines
oh_meta_idx <- grep("^Meta", oh)
qh_meta_idx <- grep("^Meta", qh)
if (length(oh_meta_idx) == 1 && length(qh_meta_idx) == 1) {
qh_clean <- sub("\\s*\\|?\\s*QC software=.*$", "", qh[qh_meta_idx])
# Clean empty meta cases:
# - "Meta"
# - "Meta "
# - "Meta   "
# - "Meta\t"
# - "Meta="
oh_clean <- sub("[=\\s]*$", "", oh[oh_meta_idx])
# Replace original vectors
oh[oh_meta_idx] <- oh_clean
qh[qh_meta_idx] <- qh_clean
}
# Compare headers
if (!identical(oh, qh)) {
warning(glue("Header mismatch for {fname}"))
next
}
# ----------------------------------
# CHECK BODY DIMENSIONS MATCH
# ----------------------------------
orig_df <- try(read_tsv(orig, skip = length(orig_header), show_col_types = FALSE), silent = TRUE)
qc_df   <- try(read_tsv(qc_path, skip = length(qc_header), show_col_types = FALSE), silent = TRUE)
if (inherits(orig_df, "try-error") || inherits(qc_df, "try-error")) {
warning(glue("Error reading dataframes for {fname}"))
next
}
if (!all(dim(orig_df) == dim(qc_df))) {
warning(glue("Dimension mismatch for {fname}"))
next
}
# ----------------------------------
# IF WE GET HERE → SUCCESS
# ----------------------------------
successful_matches[[length(successful_matches) + 1]] <- list(
file = fname,
original_path = orig,
qc_path = qc_path
)
}
warnings()
oh
oh[oh-1]
oh[1]
oh[:length(oh)-1]
oh[1:length(oh)-1]
rm(list = ls())
library(glue)
library(readr)   # for read_lines()
# -----------------------------
# PATHS
# -----------------------------
orig_root <- "/scratch3/PALAEO-RA/daily_data/final"
qc_root   <- "/scratch3/PALAEO-RA/daily_data/tmp/sef_tests"
# -----------------------------
# VARIABLES THAT DO NOT HAVE QC FILES
# -----------------------------
no_qc_vars <- c("w", "eee")
# -----------------------------
# OUTPUT LIST OF SUCCESSFUL MATCHES
# -----------------------------
successful_matches <- list()
# -----------------------------
# LIST original FILES
# -----------------------------
orig_files <- list.files(orig_root, pattern = "\\.tsv$", recursive = TRUE, full.names = TRUE)
warnings()
assign("last.warning", NULL, envir=baseenv())
warnings()
# -----------------------------
# LOOP THROUGH ORIGINAL FILES
# -----------------------------
for (orig in orig_files) {
fname <- basename(orig)
# Skip QC files
if (grepl("_qc\\.tsv$", fname)) {
next
}
# check variable and skip those that don't have qc's done on them.
header_lines <- read_lines(orig, n_max=20)
var_line     <- header_lines[grepl("^Vbl", header_lines)]
var          <- sub("^Vbl\\s+", "", var_line)
# Construct expected QC filename
qc_fname <- sub("\\.tsv$", "_qc.tsv", fname)
qc_path <- file.path(qc_root, qc_fname)
# ----------------------------------
# SKIP CHECKS OF NON-QC VARS
# ----------------------------------
if (var %in% no_qc_vars && !file.exists(qc_path)) {
# silent skip
next
}
# ----------------------------------
# CHECK IF QC FILE IS MISSING
# ----------------------------------
if (!file.exists(qc_path)) {
warning(glue("QC file missing for: {fname}"))
next
}
# ----------------------------------
# READ HEADER LINES FROM BOTH FILES
# ----------------------------------
orig_lines <- read_lines(orig, n_max = 50)
qc_lines   <- read_lines(qc_path, n_max = 50)
# extract SEF header
orig_header <- orig_lines[1:(grep("^Year", orig_lines)[1] - 1)]
qc_header   <- qc_lines[1:(grep("^Year", qc_lines)[1] - 1)]
# ----------------------------------
# CHECK HEADERS MATCH (except META)
# ----------------------------------
# Copy headers so we can modify them
oh <- orig_header[1:length(orig_header)-1]
qh <- qc_header[1:length(qc_header)-1]
# Compare headers
if (!identical(oh, qh)) {
warning(glue("Header mismatch for {fname}"))
next
}
# ----------------------------------
# CHECK BODY DIMENSIONS MATCH
# ----------------------------------
orig_df <- try(read_tsv(orig, skip = length(orig_header), show_col_types = FALSE), silent = TRUE)
qc_df   <- try(read_tsv(qc_path, skip = length(qc_header), show_col_types = FALSE), silent = TRUE)
if (inherits(orig_df, "try-error") || inherits(qc_df, "try-error")) {
warning(glue("Error reading dataframes for {fname}"))
next
}
if (!all(dim(orig_df) == dim(qc_df))) {
warning(glue("Dimension mismatch for {fname}"))
next
}
# ----------------------------------
# IF WE GET HERE → SUCCESS
# ----------------------------------
successful_matches[[length(successful_matches) + 1]] <- list(
file = fname,
original_path = orig,
qc_path = qc_path
)
}
warnings()
source("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
source("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
source("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
?trimws
debugSource("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
debugSource("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
source("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
successful_matches
nrow(successful_matches)
seq_len(nrow(successful_matches))
df
nrow(df)
seq_len(nrow(df))
names(df)
df$original_path
non_qcd_dir <- "/scratch3/PALAEO-RA/daily_data/tmp/non_qcd_files"
# write everything down
log_file <- "/scratch3/PALAEO-RA/daily_data/tmp/replacement_log.txt"
log_con  <- file(log_file, open="wt")
log_message <- function(...) {
msg <- paste(...)
writeLines(msg, log_conn)
message(msg)
}
i<-1
orig_file <- df$original_path[i]
orig_file
qc_file   <- df$qc_path[i]
orig_dir <- dirname(orig_file)
fname    <- basename(orig)
# new locations
backup_path <- file.path(non_qcd_dir, fname)
new_path    <- file.path(orig.dir, fname)
new_path    <- file.path(orig_dir, fname)
backup_path
fname
orig_file <- df$original_path[i]
qc_file   <- df$qc_path[i]
orig_dir <- dirname(orig_file)
fname    <- basename(orig_file)
fname
orig_dir
# new locations
backup_path <- file.path(non_qcd_dir, fname)
new_path    <- file.path(orig_dir, fname)
backup_path
new_path
log_message(glue::glue("Processing {fname}"))
file.exists(orig_file)
# Move original to backup folder
ok1 <- file.rename(orig_file, backup_path)
ok1
?file.rename
orig_file
backup_path
# Move QC file to original location
ok2 <- file.rename(qc, new_path)
qc_file
new_path
# Move QC file to original location
ok2 <- file.rename(qc_file, new_path)
ok2
new_path
fname    <- basename(qc_file)
orig_dir   <- dirname(orig_file)
orig_fname <- basename(orig_file)
qc_fname   <- basename(qc_file)
orig_fname
qc_fname
# new locations
backup_path <- file.path(non_qcd_dir, orig_fname)
new_path    <- file.path(orig_dir, qc_fname)
backup_path
new_path
rm(list = ls())
library(glue)
library(readr)   # for read_lines()
non_qcd_dir <- "/scratch3/PALAEO-RA/daily_data/tmp/non_qcd_files"
# write everything down
log_file <- "/scratch3/PALAEO-RA/daily_data/tmp/replacement_log.txt"
log_con  <- file(log_file, open="wt")
log_message <- function(...) {
msg <- paste(...)
writeLines(msg, log_conn)
message(msg)
}
log_message("=== Starting replacement process ===")
log_conn <- file(log_file, open="wt")
log_message <- function(...) {
msg <- paste(...)
writeLines(msg, log_conn)
message(msg)
}
log_message("=== Starting replacement process ===")
# loop through successful matches
for (i in seq_len(nrow(df))) {
orig_file <- df$original_path[i]
qc_file   <- df$qc_path[i]
orig_dir   <- dirname(orig_file)
orig_fname <- basename(orig_file)
qc_fname   <- basename(qc_file)
# new locations
backup_path <- file.path(non_qcd_dir, orig_fname)
new_path    <- file.path(orig_dir, qc_fname)
log_message(glue::glue("Processing {fname}"))
# Safety check: original exists
if (!file.exists(orig_file)) {
log_message(glue::glue("  ERROR: Original file missing ({orig}). Skipping."))
next
}
# Move original to backup folder
ok1 <- file.rename(orig_file, backup_path)
if (!ok1) {
log_message(glue::glue("  ERROR: Could not move original to backup: {orig}"))
next
}
# Move QC file to original location
ok2 <- file.rename(qc_file, new_path)
if (!ok2) {
log_message(glue::glue("  ERROR: Could not move QC file into place: {qc}"))
# try to restore original back (safety fallback)
file.rename(backup_path, orig)
next
}
log_message(glue::glue("  SUCCESS: Replaced {fname}"))
}
source("/scratch2/ccorbella/code/KF_assimilation/dataprep/qc/05_qc_replace_files.R", echo=TRUE)
# loop through successful matches
for (i in seq_len(nrow(df))) {
orig_file <- df$original_path[i]
qc_file   <- df$qc_path[i]
orig_dir   <- dirname(orig_file)
orig_fname <- basename(orig_file)
qc_fname   <- basename(qc_file)
# new locations
backup_path <- file.path(non_qcd_dir, orig_fname)
new_path    <- file.path(orig_dir, qc_fname)
log_message(glue::glue("Processing {fname}"))
# Safety check: original exists
if (!file.exists(orig_file)) {
log_message(glue::glue("  ERROR: Original file missing ({orig_file}). Skipping."))
next
}
# Move original to backup folder
ok1 <- file.rename(orig_file, backup_path)
if (!ok1) {
log_message(glue::glue("  ERROR: Could not move original to backup: {orig}"))
next
}
# Move QC file to original location
ok2 <- file.rename(qc_file, new_path)
if (!ok2) {
log_message(glue::glue("  ERROR: Could not move QC file into place: {qc_file}"))
# try to restore original back (safety fallback)
file.rename(backup_path, orig)
next
}
log_message(glue::glue("  SUCCESS: Replaced {orig_fname}"))
}
