{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take daily means and good structuring from some files. Goes together with readme file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "file_savedir = '/home/ccorbella/scratch2_symboliclink/files/station_timeseries_preprocessed/'\n",
        "file_readdir = '/home/ccorbella/scratch2_symboliclink/files/station_timeseries_orig/'\n",
        "\n",
        "# Define a function to categorize hours into morning, midday, and evening\n",
        "def tod(hour):\n",
        "    if hour < 10:\n",
        "        return \"morning\"\n",
        "    elif 10 <= hour < 16:\n",
        "        return \"midday\"\n",
        "    else:\n",
        "        return \"evening\"\n",
        "    \n",
        "def make_date_col(df):\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']], errors='coerce')\n",
        "    return df\n",
        "\n",
        "# Define weights for each hour\n",
        "default_weights = {\"morning\": 0.3, \"midday\": 0.5, \"evening\": 0.2}\n",
        "\n",
        "# select dates of interest\n",
        "def select_dates(df):\n",
        "    df = df[df['Date'] <= '1850-12-31']\n",
        "    df = df[df['Date'] >= '1806-01-01']\n",
        "    df.index -= df.index[0] # reset indices\n",
        "    return df  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bologna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "bologna = pd.read_csv(f'{file_readdir}TG_SOUID100862.txt', sep=',', header=13)\n",
        "bologna = bologna.replace(-9999, np.NaN)\n",
        "bologna = bologna.drop(columns=' SOUID')\n",
        "bologna.rename({'    DATE': 'Date', '   TG': 'TG', ' Q_TG':'Q_TG'}, inplace=True, axis='columns')\n",
        "bologna['Date'] = pd.to_datetime(bologna['Date'], format='ISO8601')\n",
        "bologna.loc[bologna['TG'].notna() & bologna['Q_TG']==1] # check how many suspect cells (Q_TG==1) and how many missing cells (Q_TG==9) are not empty\n",
        "\n",
        "bologna = select_dates(bologna)\n",
        "\n",
        "# convert units\n",
        "bologna['TMP2m'] = bologna['TG']*.1\n",
        "bologna[['Date', 'TMP2m']].to_csv(f'{file_savedir}Bologna_TMP2m.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cádiz\n",
        "\n",
        "We have 29244-13=29231 days with values in Peter's data from IMPROVE. Now let's count how many we have from the raw. We have no duplicates in dataset, and we have 29231 non-NaNs. Yay! it's the same. It looks like `CSF-TP801-819.txt` is just a small subset of `CSF-TP786-879.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "cadiz1 = pd.read_csv(f'{file_readdir}CSF-TP786-879.txt', sep=\"\\t\", header=None)\n",
        "cadiz2 = pd.read_csv(f'{file_readdir}CSF-TP801-819.txt', sep=\"\\t\", header=None)\n",
        "\n",
        "cadiz1.columns = ['Date', 'Tmin', 'Tmax', 'TMP2m', 'PRMSL']\n",
        "cadiz2.columns = cadiz1.columns\n",
        "\n",
        "cadiz1 = cadiz1.replace(-999.0, np.NaN)\n",
        "cadiz2 = cadiz2.replace(-999.0, np.NaN)\n",
        "\n",
        "# drop if all NaNs\n",
        "cadiz1 = cadiz1.dropna(subset=['TMP2m', 'PRMSL'], how='all')\n",
        "cadiz2 = cadiz2.dropna(subset=['TMP2m', 'PRMSL'], how='all')\n",
        "\n",
        "cadiz1['Date'] = pd.to_datetime(cadiz1['Date'], format=\"%d/%m/%Y\")\n",
        "cadiz2['Date'] = pd.to_datetime(cadiz2['Date'], format=\"%d/%m/%Y\")\n",
        "cadiz1 = select_dates(cadiz1)\n",
        "cadiz2 = select_dates(cadiz2)\n",
        "print(np.sum(cadiz2['TMP2m']!= cadiz1[:3323]['TMP2m']))\n",
        "\n",
        "cadiz1[['Date', 'TMP2m']].to_csv(f'{file_savedir}Cadiz_TMP2m.csv')\n",
        "cadiz1[['Date', 'PRMSL']].to_csv(f'{file_savedir}Cadiz_PRMSL.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## London\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "londonA = pd.read_csv(f'{file_readdir}/London_11_17870101-18221231_mslp.tsv',sep='\\t',header=12)\n",
        "londonB = pd.read_csv(f'{file_readdir}/London_12_18230101-18411231_mslp.tsv',sep='\\t',header=12)\n",
        "\n",
        "london = pd.concat([londonA,londonB], ignore_index=True)\n",
        "make_date_col(london)\n",
        "london = select_dates(london)\n",
        "\n",
        "london = london.groupby(\"Date\").agg(\n",
        "    PRMSL=(\"Value\", \"mean\"),\n",
        ").reset_index()\n",
        "london.to_csv(f'{file_savedir}London_PRMSL.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Milan\n",
        "We already had temperature from `PALAEO-RA_IMPROVE_Milan_17630101-18621231_ta`, which is the same as the third column of the raw file, and now I add pressure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "milan = pd.read_csv(f'{file_readdir}MI_TP763_862.txt', sep=r'\\s+', header=None)\n",
        "\n",
        "milan.columns = ['Date', 'Tmin', 'Tmax', 'ta', 'p']\n",
        "\n",
        "milan = milan.replace(-999.0, np.NaN)\n",
        "\n",
        "# drop if all NaNs\n",
        "milan = milan.dropna(subset=['ta', 'p'], how='all')\n",
        "\n",
        "milan['Date'] = pd.to_datetime(milan['Date'], format=\"%d/%m/%Y\")\n",
        "milan = milan.rename(columns={'p':'PRMSL'})\n",
        "milan = select_dates(milan)\n",
        "\n",
        "milan[['Date', 'PRMSL']].to_csv(f'{file_savedir}Milan_PRMSL.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Padova\n",
        "Ja teníem pressure i temperature fins a 1809, ara s'ha d'allargar i per no tenir 2 series de la mateixa station les concatenejo i en faig una de sola, que la utilitzaré per reemplaçar la de la carpeta USB stick Peter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "padova1 = pd.read_csv(f'{file_readdir}PD_PT766_809.txt', sep=r'\\s+', header=None)\n",
        "padova2 = pd.read_csv(f'{file_readdir}PD_PT810_853.txt', sep=r'\\s+', header=None)\n",
        "\n",
        "padova1.columns = ['Date', 'Tmin', 'Tmax', 'TMP2m', 'PRMSL']\n",
        "padova2.columns = padova1.columns\n",
        "\n",
        "padova1 = padova1.replace(-999.0, np.NaN)\n",
        "padova2 = padova2.replace(-999.0, np.NaN)\n",
        "\n",
        "# drop if all NaNs\n",
        "padova1 = padova1.dropna(subset=['TMP2m', 'PRMSL'], how='all')\n",
        "padova2 = padova2.dropna(subset=['TMP2m', 'PRMSL'], how='all')\n",
        "\n",
        "padova1['Date'] = pd.to_datetime(padova1['Date'], format=\"%d/%m/%Y\")\n",
        "padova2['Date'] = pd.to_datetime(padova2['Date'], format=\"%d/%m/%Y\")\n",
        "\n",
        "padova = pd.concat([padova1, padova2], ignore_index=True)\n",
        "padova = select_dates(padova)\n",
        "\n",
        "padova[['Date', 'TMP2m']].to_csv(f'{file_savedir}Padova_TMP2m.csv')\n",
        "padova[['Date', 'PRMSL']].to_csv(f'{file_savedir}Padova_PRMSL.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "paris = pd.read_csv('/home/ccorbella/scratch2_symboliclink/files/station_timeseries_orig/Paris_4_17850101-18720615_mslp.tsv',sep='\\t',header=12)\n",
        "make_date_col(paris)\n",
        "paris = paris.rename(columns={'Value':'PRMSL'})\n",
        "\n",
        "paris = select_dates(paris)\n",
        "paris[['Date','PRMSL']].to_csv(f'{file_savedir}Paris_PRMSL.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prague"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>TG</th>\n",
              "      <th>Q_TG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3711</th>\n",
              "      <td>1785-02-28</td>\n",
              "      <td>-213.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30641</th>\n",
              "      <td>1858-11-23</td>\n",
              "      <td>-150.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87607</th>\n",
              "      <td>2014-11-11</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87608</th>\n",
              "      <td>2014-11-12</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87609</th>\n",
              "      <td>2014-11-13</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87610</th>\n",
              "      <td>2014-11-14</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87611</th>\n",
              "      <td>2014-11-15</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date     TG  Q_TG\n",
              "3711  1785-02-28 -213.0     1\n",
              "30641 1858-11-23 -150.0     1\n",
              "87607 2014-11-11  120.0     1\n",
              "87608 2014-11-12  120.0     1\n",
              "87609 2014-11-13  120.0     1\n",
              "87610 2014-11-14  120.0     1\n",
              "87611 2014-11-15  120.0     1"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prague = pd.read_csv(f'{file_readdir}TG_STAID000027.txt', sep=',', header=14)\n",
        "prague = prague.replace(-9999, np.NaN)\n",
        "prague = prague.drop(columns=' SOUID')\n",
        "prague.rename({'    DATE': 'Date', '   TG': 'TG', ' Q_TG':'Q_TG'}, inplace=True, axis='columns')\n",
        "prague['Date'] = pd.to_datetime(prague['Date'], format='ISO8601')\n",
        "prague.loc[prague['TG'].notna() & prague['Q_TG']==1] # check how many suspect cells (Q_TG==1) and how many missing cells (Q_TG==9) are not empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "prague = select_dates(prague)\n",
        "\n",
        "prague['TMP2m'] = prague['TG']*.1\n",
        "prague[['Date','TMP2m']].to_csv(f'{file_savedir}Prague_TMP2m.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stockholm\n",
        "Same as Padova, without need for concatenating files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "stockholm = pd.read_csv(f'{file_readdir}ST_TP756_880.txt', sep=r'\\s+', header=None)\n",
        "\n",
        "stockholm.columns = ['Date', 'TMP2m', 'PRMSL']\n",
        "\n",
        "stockholm = stockholm.replace(-999.0, np.NaN)\n",
        "\n",
        "# drop if all NaNs\n",
        "stockholm = stockholm.dropna(subset=['TMP2m', 'PRMSL'], how='all')\n",
        "\n",
        "stockholm['Date'] = pd.to_datetime(stockholm['Date'], format=\"%d/%m/%Y\")\n",
        "stockholm = select_dates(stockholm)\n",
        "\n",
        "stockholm[['Date', 'PRMSL']].to_csv(f'{file_savedir}Stockholm_PRMSL.csv')\n",
        "stockholm[['Date', 'TMP2m']].to_csv(f'{file_savedir}Stockholm_TMP2m.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Torino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ta = pd.read_csv(f'{file_readdir}torino_tmin-tmax.txt',sep='\\t', header=None)\n",
        "df_ta.columns=['Day', 'Month', 'Year', 'tmin','tmax']\n",
        "make_date_col(df_ta)\n",
        "df_ta = select_dates(df_ta)\n",
        "df_ta['TMP2m'] = (df_ta['tmin'] + df_ta['tmax'])/2\n",
        "df_ta[['Date', 'TMP2m']].to_csv(f'{file_savedir}not_to_use/Torino_TMP2m.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_p = pd.read_csv(f'{file_readdir}TorinoPR792_953.csv', sep='\\t')\n",
        "df_p.columns=['Year','Month','Day','Hour','PRMSL']\n",
        "make_date_col(df_p)\n",
        "df_p = select_dates(df_p)\n",
        "df_p[['PRMSL','Date']].to_csv(f'{file_savedir}Torino_PRMSL.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uppsala"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "uppsala = pd.read_csv(f'{file_readdir}UPP_TP722_870.txt', sep=r'\\s+', header=None)\n",
        "\n",
        "uppsala.columns = ['Date', 'TMP2m', 'unknown_A', 'PRMSL', 'unknown_B']\n",
        "\n",
        "uppsala = uppsala.replace(-999.0, np.NaN)\n",
        "\n",
        "# drop if all NaNs\n",
        "uppsala = uppsala.dropna(subset=['TMP2m', 'PRMSL'], how='all')\n",
        "\n",
        "uppsala['Date'] = pd.to_datetime(uppsala['Date'], format=\"%d/%m/%Y\")\n",
        "uppsala = select_dates(uppsala)\n",
        "\n",
        "uppsala[['Date', 'PRMSL']].to_csv(f'{file_savedir}Uppsala_PRMSL.csv')\n",
        "uppsala[['Date', 'TMP2m']].to_csv(f'{file_savedir}Uppsala_TMP2m.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# València"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Day</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "      <th>Hour</th>\n",
              "      <th>TMP2m</th>\n",
              "      <th>Bar(p)</th>\n",
              "      <th>Bar(l)</th>\n",
              "      <th>Higro1</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time_of_Day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1806</td>\n",
              "      <td>7</td>\n",
              "      <td>6.75</td>\n",
              "      <td>6.75</td>\n",
              "      <td>6.75</td>\n",
              "      <td>6.75</td>\n",
              "      <td>1806-01-01</td>\n",
              "      <td>morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1806</td>\n",
              "      <td>13</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1806-01-01</td>\n",
              "      <td>midday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1806</td>\n",
              "      <td>18</td>\n",
              "      <td>7.50</td>\n",
              "      <td>7.50</td>\n",
              "      <td>7.50</td>\n",
              "      <td>7.50</td>\n",
              "      <td>1806-01-01</td>\n",
              "      <td>evening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1806</td>\n",
              "      <td>7</td>\n",
              "      <td>6.25</td>\n",
              "      <td>6.25</td>\n",
              "      <td>6.25</td>\n",
              "      <td>6.25</td>\n",
              "      <td>1806-01-02</td>\n",
              "      <td>morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1806</td>\n",
              "      <td>13</td>\n",
              "      <td>7.50</td>\n",
              "      <td>7.50</td>\n",
              "      <td>7.50</td>\n",
              "      <td>7.50</td>\n",
              "      <td>1806-01-02</td>\n",
              "      <td>midday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47738</th>\n",
              "      <td>27</td>\n",
              "      <td>12</td>\n",
              "      <td>1850</td>\n",
              "      <td>12</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1850-12-27</td>\n",
              "      <td>midday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47739</th>\n",
              "      <td>27</td>\n",
              "      <td>12</td>\n",
              "      <td>1850</td>\n",
              "      <td>18</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1850-12-27</td>\n",
              "      <td>evening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47740</th>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>1850</td>\n",
              "      <td>7</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1850-12-28</td>\n",
              "      <td>morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47741</th>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>1850</td>\n",
              "      <td>12</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1850-12-28</td>\n",
              "      <td>midday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47742</th>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>1850</td>\n",
              "      <td>18</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1850-12-28</td>\n",
              "      <td>evening</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36796 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Day  Month  Year  Hour  TMP2m  Bar(p)  Bar(l)  Higro1       Date  \\\n",
              "0        1      1  1806     7   6.75    6.75    6.75    6.75 1806-01-01   \n",
              "1        1      1  1806    13   8.00    8.00    8.00    8.00 1806-01-01   \n",
              "2        1      1  1806    18   7.50    7.50    7.50    7.50 1806-01-01   \n",
              "3        2      1  1806     7   6.25    6.25    6.25    6.25 1806-01-02   \n",
              "4        2      1  1806    13   7.50    7.50    7.50    7.50 1806-01-02   \n",
              "...    ...    ...   ...   ...    ...     ...     ...     ...        ...   \n",
              "47738   27     12  1850    12   7.00    7.00    7.00    7.00 1850-12-27   \n",
              "47739   27     12  1850    18   7.00    7.00    7.00    7.00 1850-12-27   \n",
              "47740   28     12  1850     7   4.00    4.00    4.00    4.00 1850-12-28   \n",
              "47741   28     12  1850    12   7.00    7.00    7.00    7.00 1850-12-28   \n",
              "47742   28     12  1850    18   7.00    7.00    7.00    7.00 1850-12-28   \n",
              "\n",
              "      Time_of_Day  \n",
              "0         morning  \n",
              "1          midday  \n",
              "2         evening  \n",
              "3         morning  \n",
              "4          midday  \n",
              "...           ...  \n",
              "47738      midday  \n",
              "47739     evening  \n",
              "47740     morning  \n",
              "47741      midday  \n",
              "47742     evening  \n",
              "\n",
              "[36796 rows x 10 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valencia_raw = pd.read_csv(f'{file_savedir}Valencia_concatenated.csv',\n",
        "                           dtype={'Day': 'Int64', 'Month': 'Int64', 'Year': 'Int64', 'Hour': 'Int64'})\n",
        "\n",
        "valencia_raw = valencia_raw.iloc[:,:9]\n",
        "valencia_raw = valencia_raw.dropna(subset=['Day', 'Month','Year','Hour'])\n",
        "valencia_raw = valencia_raw.dropna(subset=['Term', 'Bar(p)', 'Bar(l)'])\n",
        "\n",
        "valencia_raw[\"Hour\"] = pd.to_numeric(valencia_raw[\"Hour\"], errors='coerce')\n",
        "valencia_raw[\"Date\"] = pd.to_datetime(valencia_raw[\"Date\"])\n",
        "\n",
        "valencia_raw[\"Time_of_Day\"] = valencia_raw[\"Hour\"].apply(tod)\n",
        "valencia_raw[\"Term\"] = pd.to_numeric(valencia_raw['Term'], errors='coerce')\n",
        "valencia_raw[\"Bar(p)\"] = pd.to_numeric(valencia_raw['Term'], errors='coerce')\n",
        "valencia_raw[\"Bar(l)\"] = pd.to_numeric(valencia_raw['Term'], errors='coerce')\n",
        "valencia_raw[\"Higro1\"] = pd.to_numeric(valencia_raw['Term'], errors='coerce')\n",
        "valencia_raw = valencia_raw.rename(columns = {'Term':'TMP2m'})\n",
        "valencia_raw = select_dates(valencia_raw)\n",
        "valencia_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1136354/2350205888.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  valencia = valencia_raw.groupby('Date').apply(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute weighted averages for each day that is valid\n",
        "valid_days = valencia_raw.groupby('Date')['Time_of_Day'].nunique()\n",
        "valid_dates = valid_days[valid_days==3].index # select only dates w 3 obs\n",
        "\n",
        "valencia_raw = valencia_raw[valencia_raw['Date'].isin(valid_dates)]\n",
        "\n",
        "valencia = valencia_raw.groupby('Date').apply(\n",
        "    lambda group: (group['TMP2m'] * group['Time_of_Day'].map(default_weights)).sum()/group['Time_of_Day'].map(default_weights).sum()\n",
        ")\n",
        "valencia = pd.DataFrame({'TMP2m': valencia})\n",
        "valencia = valencia.reset_index()\n",
        "valencia.to_csv(f'{file_savedir}Valencia_TMP2m.csv')\n",
        "\n",
        "# percentage of days when there at least one and at most 2 observations\n",
        "obs_per_day = valencia_raw.groupby('Date').size().reset_index(name='obs_per_day')\n",
        "obs_per_day[obs_per_day['obs_per_day']<3].shape[0]/valencia.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pressure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "valencia_p = valencia_raw.groupby(\"Date\").agg(\n",
        "    PRMSL=(\"Bar(p)\", \"mean\"),\n",
        ").reset_index()\n",
        "\n",
        "# convert to hPa\n",
        "valencia_p['PRMSL'] = 1013.25*valencia_p['PRMSL']/29.92\n",
        "\n",
        "valencia_p.to_csv(f'{file_savedir}Valencia_PRMSL.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ylitornio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "yli = pd.read_csv(f'{file_readdir}CLIM_Data_Ylitornio_1800_1838.csv',\n",
        "                  delimiter=\";\", skiprows=6, encoding=\"Windows-1252\")\n",
        "\n",
        "yli = yli.iloc[:,:7]\n",
        "\n",
        "try: yli = yli.drop(columns={'Unnamed: 3', 'Observation hour'})\n",
        "except: print('already cropped df')\n",
        "\n",
        "yli = yli.rename(columns={'Air pressure': 'PRMSL', 'Temperature':'TMP2m'})\n",
        "\n",
        "yli = make_date_col(yli)\n",
        "yli = select_dates(yli)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>PRMSL</th>\n",
              "      <th>TMP2m</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1800</th>\n",
              "      <td>1810</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>25.40</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>1810-12-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087</th>\n",
              "      <td>1810</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>25.48</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>1810-12-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7248</th>\n",
              "      <td>1826</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>25.55</td>\n",
              "      <td>-6.7</td>\n",
              "      <td>1826-11-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7613</th>\n",
              "      <td>1826</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>1826-11-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Year  Month  Day  PRMSL  TMP2m       Date\n",
              "1800  1810     12    6  25.40  -10.0 1810-12-06\n",
              "5087  1810     12    6  25.48  -10.0 1810-12-06\n",
              "7248  1826     11    5  25.55   -6.7 1826-11-05\n",
              "7613  1826     11    5    NaN   -2.0 1826-11-05"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check for typos in dates\n",
        "yli[yli.duplicated(subset=['Date'], keep=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ammend the typos and redo date column\n",
        "yli.at[3147,'Year']=1809\n",
        "yli.at[6799, 'Year']=1819\n",
        "yli.at[8960, 'Year']=1825\n",
        "\n",
        "# convert to hPa\n",
        "yli['PRMSL'] = 1013.25*yli['PRMSL']/29.92\n",
        "\n",
        "# split into Pressure and Temperature and save\n",
        "yli[['Date', 'PRMSL']].to_csv(f'{file_savedir}Ylitornio_PRMSL.csv')\n",
        "yli[['Date', 'TMP2m']].to_csv(f'{file_savedir}Ylitornio_TMP2m.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zwanenburg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(f'{file_readdir}DeBilt_1_17430101-18501231_mslp.tsv', sep='\\t', header=12)\n",
        "make_date_col(df)\n",
        "df = select_dates(df)\n",
        "\n",
        "df = df.groupby('Date').agg(PRMSL=('Value', 'mean')).reset_index()\n",
        "df.to_csv(f'{file_savedir}Zwanenburg_PRMSL.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "carlota_envi",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
